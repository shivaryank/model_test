{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba89b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train processed:\n",
      "          id   Age  DailyRate  DistanceFromHome  Education  EmployeeCount  \\\n",
      "163    163.0  27.0     1302.0               2.0        2.0            1.0   \n",
      "427    427.0  32.0     1476.0              28.0        2.0            1.0   \n",
      "1239  1239.0  44.0     1275.0               9.0        2.0            1.0   \n",
      "266    266.0  46.0     1320.0              24.0        4.0            1.0   \n",
      "148    148.0  42.0      442.0               1.0        4.0            1.0   \n",
      "\n",
      "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  ...  \\\n",
      "163                       2.0        62.0             3.0       2.0  ...   \n",
      "427                       1.0        81.0             3.0       2.0  ...   \n",
      "1239                      3.0        95.0             3.0       1.0  ...   \n",
      "266                       4.0        48.0             2.0       3.0  ...   \n",
      "148                       1.0        72.0             2.0       3.0  ...   \n",
      "\n",
      "      JobRole_Research Director  JobRole_Research Scientist  \\\n",
      "163                         0.0                         1.0   \n",
      "427                         0.0                         0.0   \n",
      "1239                        0.0                         0.0   \n",
      "266                         0.0                         1.0   \n",
      "148                         0.0                         0.0   \n",
      "\n",
      "      JobRole_Sales Executive  JobRole_Sales Representative  \\\n",
      "163                       0.0                           0.0   \n",
      "427                       1.0                           0.0   \n",
      "1239                      0.0                           1.0   \n",
      "266                       0.0                           0.0   \n",
      "148                       0.0                           0.0   \n",
      "\n",
      "      MaritalStatus_Divorced  MaritalStatus_Married  MaritalStatus_Single  \\\n",
      "163                      0.0                    0.0                   1.0   \n",
      "427                      0.0                    1.0                   0.0   \n",
      "1239                     0.0                    0.0                   1.0   \n",
      "266                      0.0                    1.0                   0.0   \n",
      "148                      0.0                    0.0                   1.0   \n",
      "\n",
      "      Over18_Y  OverTime_No  OverTime_Yes  \n",
      "163        1.0          1.0           0.0  \n",
      "427        1.0          1.0           0.0  \n",
      "1239       1.0          0.0           1.0  \n",
      "266        1.0          1.0           0.0  \n",
      "148        1.0          0.0           1.0  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "\n",
      "X_test processed:\n",
      "          id   Age  DailyRate  DistanceFromHome  Education  EmployeeCount  \\\n",
      "1600  1600.0  28.0      868.0              19.0        3.0            1.0   \n",
      "482    482.0  36.0      557.0               4.0        2.0            1.0   \n",
      "203    203.0  28.0      465.0               5.0        3.0            1.0   \n",
      "49      49.0  27.0      994.0               1.0        3.0            1.0   \n",
      "1289  1289.0  40.0      890.0               1.0        4.0            1.0   \n",
      "\n",
      "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  ...  \\\n",
      "1600                      3.0        78.0             3.0       1.0  ...   \n",
      "482                       3.0        62.0             3.0       1.0  ...   \n",
      "203                       1.0        83.0             3.0       1.0  ...   \n",
      "49                        4.0        86.0             3.0       2.0  ...   \n",
      "1289                      4.0        86.0             3.0       1.0  ...   \n",
      "\n",
      "      JobRole_Research Director  JobRole_Research Scientist  \\\n",
      "1600                        NaN                         NaN   \n",
      "482                         NaN                         NaN   \n",
      "203                         0.0                         0.0   \n",
      "49                          0.0                         1.0   \n",
      "1289                        NaN                         NaN   \n",
      "\n",
      "      JobRole_Sales Executive  JobRole_Sales Representative  \\\n",
      "1600                      NaN                           NaN   \n",
      "482                       NaN                           NaN   \n",
      "203                       0.0                           0.0   \n",
      "49                        0.0                           0.0   \n",
      "1289                      NaN                           NaN   \n",
      "\n",
      "      MaritalStatus_Divorced  MaritalStatus_Married  MaritalStatus_Single  \\\n",
      "1600                     NaN                    NaN                   NaN   \n",
      "482                      NaN                    NaN                   NaN   \n",
      "203                      1.0                    0.0                   0.0   \n",
      "49                       0.0                    1.0                   0.0   \n",
      "1289                     NaN                    NaN                   NaN   \n",
      "\n",
      "      Over18_Y  OverTime_No  OverTime_Yes  \n",
      "1600       NaN          NaN           NaN  \n",
      "482        NaN          NaN           NaN  \n",
      "203        1.0          0.0           1.0  \n",
      "49         1.0          0.0           1.0  \n",
      "1289       NaN          NaN           NaN  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/shiv.kumar/Downloads/train.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop('Attrition', axis=1)\n",
    "y = data['Attrition']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Selecting the categorical features\n",
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "# Preprocess categorical features using OneHotEncoder\n",
    "#categorical_features = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']\n",
    "\n",
    "# Subset the categorical features from the training and testing sets\n",
    "X_train_categorical = X_train[categorical_features]\n",
    "X_test_categorical = X_test[categorical_features]\n",
    "\n",
    "# Apply OneHotEncoder to the categorical features\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train_categorical)\n",
    "X_test_encoded = encoder.transform(X_test_categorical)\n",
    "\n",
    "# Convert the encoded categorical features back into DataFrames\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Concatenate the encoded categorical features with the numerical features\n",
    "X_train_processed = pd.concat([X_train.drop(categorical_features, axis=1), X_train_encoded], axis=1)\n",
    "X_test_processed = pd.concat([X_test.drop(categorical_features, axis=1), X_test_encoded], axis=1)\n",
    "\n",
    "# Print the processed datasets\n",
    "print(\"X_train processed:\")\n",
    "print(X_train_processed.head())\n",
    "print(\"\\nX_test processed:\")\n",
    "print(X_test_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75d3cf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train a logistic regression model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions on the training and testing sets\u001b[39;00m\n\u001b[0;32m     13\u001b[0m train_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_train_processed)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Drop the 'id' column from the processed datasets\n",
    "X_train_processed = X_train_processed.drop('id', axis=1)\n",
    "X_test_processed = X_test_processed.drop('id', axis=1)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "train_predictions = model.predict_proba(X_train_processed)[:, 1]\n",
    "test_predictions = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Calculate ROC AUC scores\n",
    "train_roc_auc = roc_auc_score(y_train, train_predictions)\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "\n",
    "# Print the ROC AUC scores\n",
    "print(\"Train ROC AUC:\", train_roc_auc)\n",
    "print(\"Test ROC AUC:\", test_roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e113e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/shiv.kumar/Downloads/train.csv')\n",
    "\n",
    "# Splitting the data into features and target\n",
    "X = data.drop('Attrition', axis=1)\n",
    "y = data['Attrition']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Selecting the categorical features\n",
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "# Encoding the categorical features\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_train_cat = encoder.fit_transform(X_train[categorical_features])\n",
    "X_test_cat = encoder.transform(X_test[categorical_features])\n",
    "\n",
    "# Dropping the original categorical features\n",
    "X_train = X_train.drop(categorical_features, axis=1)\n",
    "X_test = X_test.drop(categorical_features, axis=1)\n",
    "\n",
    "\n",
    "# Concatenating the encoded categorical features\n",
    "X_train = pd.concat([X_train, pd.DataFrame(X_train_cat, index=X_train.index)], axis=1)\n",
    "X_test = pd.concat([X_test, pd.DataFrame(X_test_cat, index=X_test.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88658ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>43</td>\n",
       "      <td>427</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1038</td>\n",
       "      <td>38</td>\n",
       "      <td>506</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>55</td>\n",
       "      <td>287</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1657</td>\n",
       "      <td>31</td>\n",
       "      <td>783</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>814</td>\n",
       "      <td>40</td>\n",
       "      <td>607</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Age  DailyRate  DistanceFromHome  Education  EmployeeCount  \\\n",
       "394    394   43        427                 7          3              1   \n",
       "1038  1038   38        506                 5          3              1   \n",
       "869    869   55        287                23          3              1   \n",
       "1657  1657   31        783                28          4              1   \n",
       "814    814   40        607                 2          3              1   \n",
       "\n",
       "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  ...   19  \\\n",
       "394                         2          66               4         2  ...  0.0   \n",
       "1038                        4          94               3         1  ...  0.0   \n",
       "869                         3          72               2         2  ...  0.0   \n",
       "1657                        4          60               3         2  ...  0.0   \n",
       "814                         4          87               3         3  ...  0.0   \n",
       "\n",
       "       20   21   22   23   24   25   26   27   28  \n",
       "394   0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "1038  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  \n",
       "869   1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  \n",
       "1657  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  \n",
       "814   0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.head()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6b65e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiv.kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shiv.kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\shiv.kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Droping the 'id' column\n",
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)\n",
    "\n",
    "# Training the model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794acb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
